{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"TOGETHER_API_KEY\"] = (\n",
    "    \"1fd84ed39d1c9253221efa2323baeb1c04375a6fd60d14fd186a1a78137f7c6f\"\n",
    ")\n",
    "os.environ[\"WCD_URL\"] = \"https://whrf9muprazmpyngw8pq.c0.us-east1.gcp.weaviate.cloud\"\n",
    "os.environ[\"WCD_API_KEY\"] = \"MbL4bdQ8h2fDJqOjSI7QbUtCbn9rJW7k94ir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from typing import Any, Dict, Iterator, List, Optional\n",
    "from together import Together\n",
    "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from langchain_core.outputs import GenerationChunk\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field, PrivateAttr\n",
    "import json\n",
    "\n",
    "\n",
    "class AccessibilityIssue(BaseModel):\n",
    "    \"\"\"Schema for accessibility issues.\"\"\"\n",
    "\n",
    "    Title: str = Field(description=\"Title of the issue\")\n",
    "    Description: str = Field(description=\"Detailed description of the issue\")\n",
    "    Suggestion: str = Field(description=\"Suggested fix for the issue\")\n",
    "    Importance_score: float = Field(description=\"Importance score between 0.0 and 1.0\")\n",
    "\n",
    "\n",
    "class AccessibilityResponse(BaseModel):\n",
    "    \"\"\"Schema for the complete accessibility response.\"\"\"\n",
    "\n",
    "    issues: Dict[str, AccessibilityIssue] = Field(\n",
    "        description=\"Dictionary of accessibility issues\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_context(file_path: str) -> str:\n",
    "    \"\"\"Load context from a file.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "class TogetherVisionLLM(LLM):\n",
    "    \"\"\"A custom LLM that implements Together's Vision model capabilities.\n",
    "\n",
    "    This LLM allows you to send both text and image inputs to Together's vision models,\n",
    "    particularly designed for use with models like meta-llama/Llama-Vision-Free.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            model = TogetherVisionLLM(\n",
    "                model_name=\"meta-llama/Llama-Vision-Free\",\n",
    "                temperature=0.9,\n",
    "                top_p=0.7\n",
    "            )\n",
    "            result = model.invoke(\n",
    "                \"Describe this image\",\n",
    "                image_url=\"https://example.com/image.png\"\n",
    "            )\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = Field(\n",
    "        default=\"meta-llama/Llama-Vision-Free\",\n",
    "        description=\"The name of the Together model to use\",\n",
    "    )\n",
    "    temperature: float = Field(default=0.9, description=\"Sampling temperature to use\")\n",
    "    top_p: float = Field(default=0.7, description=\"Top p sampling parameter\")\n",
    "    top_k: int = Field(default=50, description=\"Top k sampling parameter\")\n",
    "    repetition_penalty: float = Field(\n",
    "        default=1.0, description=\"Repetition penalty parameter\"\n",
    "    )\n",
    "\n",
    "    _client: Together = PrivateAttr()\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._client = Together()\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        image_url: Optional[str] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        \"\"\"Run the LLM on the given input.\n",
    "\n",
    "        Args:\n",
    "            prompt: The text prompt to generate from.\n",
    "            stop: Stop words (not supported in this implementation).\n",
    "            run_manager: Callback manager for the run.\n",
    "            image_url: Optional URL to an image to analyze.\n",
    "            **kwargs: Additional keyword arguments passed to the Together API.\n",
    "\n",
    "        Returns:\n",
    "            The model output as a string.\n",
    "        \"\"\"\n",
    "        if stop is not None:\n",
    "            raise ValueError(\n",
    "                \"stop kwargs are not permitted for Together Vision models.\"\n",
    "            )\n",
    "\n",
    "        # Construct the message content\n",
    "        content = [{\"role\": \"user\", \"content\": []}]\n",
    "\n",
    "        # Add text prompt\n",
    "        content[0][\"content\"].append({\"type\": \"text\", \"text\": prompt})\n",
    "\n",
    "        # Add image if provided\n",
    "        if image_url:\n",
    "            content[0][\"content\"].append(\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            )\n",
    "\n",
    "        # Make the API call\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=content,\n",
    "            temperature=self.temperature,\n",
    "            top_p=self.top_p,\n",
    "            top_k=self.top_k,\n",
    "            repetition_penalty=self.repetition_penalty,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        image_url: Optional[str] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[GenerationChunk]:\n",
    "        \"\"\"Stream is not currently supported for Together Vision models.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"Streaming is not currently supported for Together Vision models.\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return identifying parameters.\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"repetition_penalty\": self.repetition_penalty,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of LLM.\"\"\"\n",
    "        return \"together_vision\"\n",
    "\n",
    "\n",
    "# vision_color_contrast_checker = TogetherVisionLLM(\n",
    "#     model_name=\"meta-llama/Llama-Vision-Free\",\n",
    "#     temperature=1.0,\n",
    "#     top_p=0.8,\n",
    "#     top_k=10,\n",
    "#     repetition_penalty=1.0\n",
    "# )\n",
    "\n",
    "# font_checker = TogetherVisionLLM(\n",
    "#     model_name=\"meta-llama/Llama-Vision-Free\",\n",
    "#     temperature=0.8,\n",
    "#     top_p=0.7,\n",
    "#     top_k=25,\n",
    "#     repetition_penalty=1.0\n",
    "# )\n",
    "\n",
    "# color_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "#         You are a Expert Color Contrast Tester. Choosing the correct colors is really important\n",
    "#         for any design to be accessible for a large number of people having various vision impairments.\n",
    "#         Assume that the user is a newbie and has no prior knowledge of color contrast.\n",
    "\n",
    "#         CONTEXT: {context}\n",
    "\n",
    "#         TASK:\n",
    "#         Your task is to return instances within the image wherever the above conditions are not met.\n",
    "#         You have to return a JSON array of each instance describing its flaws with specific location of the flaw.\n",
    "\n",
    "#         Return ONLY the JSON in the given format, do not return anything else.\n",
    "#         If there are no issues just return an empty JSON.\n",
    "#         \"\"\")\n",
    "\n",
    "# with open('coloring_for_colorblindness.txt') as f:\n",
    "#     r1 = vision_color_contrast_checker.invoke(\n",
    "#         f\"\"\"You are a Expert Color Contrast Tester. Choosing the correct colors is really important\n",
    "#         for any design to be accessible for a large number of people having various vision impairments.\n",
    "#         Assume that the user is a newbie and has no prior knowledge of color contrast.\n",
    "#         Start the output with JSON \"{{\"\n",
    "\n",
    "#         CONTEXT:  {f.read()}\n",
    "#         TASK:\n",
    "#             Your task is to return instances within the image wherever the above conditions are not met. You have to return a JSON array of each instance describing its flaws with specific location of the flaw.\n",
    "#             return ONLY the JSON in the given format, do not return anything else. If there are no issues just return an empty JSON. :\n",
    "#         OUTPUT FORMAT:\n",
    "#             {{\n",
    "#             \"Issue1\": {{\n",
    "#                 \"Title\": \" ... \",\n",
    "#                 \"Description\": \" ... \",\n",
    "#                 \"Suggestion\": \" ... \",\n",
    "#                 \"Importance_score\": <float value between 0.0 to 1.0>\n",
    "#             }},\n",
    "#             \"Issue2\": {{\n",
    "#                 \"Title\": \" ... \",\n",
    "#                 \"Description\": \" ... \",\n",
    "#                 \"Suggestion\": \" ... \",\n",
    "#                 \"Importance_score\": <float value between 0.0 to 1.0>\n",
    "#             }},\n",
    "#             ...\n",
    "#             }}\n",
    "#     \"\"\",\n",
    "#         image_url=\"https://cdn.discordapp.com/attachments/699317920022397019/1302381353504997428/Summer-Flyer-and-Poster.png?ex=6727e8a7&is=67269727&hm=57ec1e6d9b8098efc7e78885c78f1a4cbafdbee9a46f651427568ea6872def93&\"\n",
    "#     )\n",
    "# print(r1)\n",
    "\n",
    "# with open('font_for_vision.txt', encoding='utf8') as f:\n",
    "#     r2 = font_checker.invoke(\n",
    "#         f\"\"\"You are a Expert Font Style Evaluater. Using information in the context provided, make suggestions\n",
    "#              for the design to be accessible for a large number of people having various vision impairments. start the output with \"JSON:\"\n",
    "#         CONTEXT:\n",
    "#         {f.read()}\n",
    "\n",
    "#         TASK:\n",
    "#             Your task is to return instances within the image wherever the above conditions are not met. You have to return a JSON array of each instance describing its flaws with specific location of the flaw.\n",
    "#             return ONLY the JSON in the given format, do not return anything else. If there are no issues just return an empty JSON. :\n",
    "#         OUTPUT FORMAT:\n",
    "#             {{\n",
    "#             \"Issue1\": {{\n",
    "#                 \"Title\": \" ... \",\n",
    "#                 \"Description\": \" ... \",\n",
    "#                 \"Suggestion\": \" ... \",\n",
    "#                 \"Importance_score\": <float value between 0.0 to 1.0>\n",
    "#             }},\n",
    "#             \"Issue2\": {{\n",
    "#                 \"Title\": \" ... \",\n",
    "#                 \"Description\": \" ... \",\n",
    "#                 \"Suggestion\": \" ... \",\n",
    "#                 \"Importance_score\": <float value between 0.0 to 1.0>\n",
    "#             }},\n",
    "#             ...\n",
    "#             }}\n",
    "#     \"\"\",\n",
    "#         image_url=\"https://cdn.discordapp.com/attachments/699317920022397019/1302381353504997428/Summer-Flyer-and-Poster.png?ex=6727e8a7&is=67269727&hm=57ec1e6d9b8098efc7e78885c78f1a4cbafdbee9a46f651427568ea6872def93&\"\n",
    "#     )\n",
    "# print(r2)\n",
    "# designleader = ChatTogether(\n",
    "#     # together_api_key=\"YOUR_API_KEY\",\n",
    "#     model=\"meta-llama/Llama-Vision-Free\",\n",
    "# )\n",
    "\n",
    "# # stream the response back from the model\n",
    "# chat.invoke(\"Combine output of both the models and provide final feedback to the junior designer as a JSON file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accessibility_chain():\n",
    "    \"\"\"Create the main accessibility checking chain.\"\"\"\n",
    "\n",
    "    # Initialize models\n",
    "    color_model = TogetherVisionLLM(\n",
    "        # model_name=\"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\", temperature=1.0, top_p=0.8, top_k=10\n",
    "        model_name=\"meta-llama/Llama-Vision-Free\", temperature=1.0, top_p=0.8, top_k=10\n",
    "    )\n",
    "\n",
    "    font_model = TogetherVisionLLM(\n",
    "        model_name=\"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\", temperature=0.8, top_p=0.7, top_k=25\n",
    "        # model_name=\"meta-llama/Llama-Vision-Free\", temperature=0.8, top_p=0.7, top_k=25\n",
    "    )\n",
    "\n",
    "    final_model = TogetherVisionLLM(\n",
    "        # model_name=\"Qwen/Qwen2.5-72B-Instruct-Turbo\", temperature=0.7, top_p=0.7, top_k=50\n",
    "        model_name=\"meta-llama/Llama-Vision-Free\", temperature=0.7, top_p=0.7, top_k=50\n",
    "    )\n",
    "\n",
    "    # Create prompts\n",
    "    color_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"You are a Expert Color Contrast Tester. Choosing the correct colors is really important\n",
    "        for any design to be accessible for a large number of people having various vision impairments.\n",
    "        Assume that the user is a newbie and has no prior knowledge of color contrast.\n",
    "\n",
    "        CONTEXT:  {context}\n",
    "        TASK:\n",
    "            Your task is to return instances within the image wherever the above conditions are not met. You have to return a JSON array of each instance describing its flaws with specific location of the flaw.\n",
    "            return ONLY the data in the given format, do not return anything else. If there are no issues just return an EOL Character. :\n",
    "        OUTPUT FORMAT:\n",
    "  \n",
    "            1.  \"Title\": \" ... \",\n",
    "                \"Description\": \" ... \",\n",
    "                \"Suggestion\": \" ... \",\n",
    "                \"Importance_score\": <float value between 0.0 to 1.0>\n",
    "            2.  \"Title\": \" ... \",\n",
    "            ...\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    font_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"You are a Expert Font Style Evaluater. Using information in the context provided, make suggestions\n",
    "             for the design to be accessible for a large number of people having various vision impairments\n",
    "        CONTEXT:\n",
    "        {context}\n",
    "\n",
    "        TASK:\n",
    "            Your task is to return instances within the image wherever the above conditions are not met. You have to return a JSON array of each instance describing its flaws with specific location of the flaw.\n",
    "            return ONLY the data in the given format, do not return anything else. If there are no issues just return an EOL Character. :\n",
    "        OUTPUT FORMAT:\n",
    "  \n",
    "            1.  \"Title\": \" ... \",\n",
    "                \"Description\": \" ... \",\n",
    "                \"Suggestion\": \" ... \",\n",
    "                \"Importance_score\": <float value between 0.0 to 1.0>\n",
    "            2.  \"Title\": \" ... \",\n",
    "            ...\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    final_prompt = PromptTemplate.from_template(\n",
    "        \"\"\" You are the Design Leader, you have been provided the opinions of two experts on the design. \n",
    "        TASK:\n",
    "        Aggregate output of both the Experts and sort the results based on their importance for creating an accesible design . Provide final feedback to the junior designer as a JSON file\n",
    "        \n",
    "        OUTPUT FORMAT:\n",
    "        {{\n",
    "            \"Issue1\": {{\n",
    "                \"Title\": \"...\",\n",
    "                \"Description\": \"...\",\n",
    "                \"Suggestion\": \"...\",\n",
    "                \"Importance_score\": <float between 0.0 to 1.0>\n",
    "            }},\n",
    "            ...\n",
    "        }}\n",
    "\n",
    "        Expert1 opinion: {color_result}\n",
    "\n",
    "        Expert2 opinion: {font_result}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create output parser\n",
    "    output_parser = JsonOutputParser(pydantic_object=AccessibilityResponse)\n",
    "\n",
    "    # Create individual chains\n",
    "    color_chain = (\n",
    "        {\"context\": RunnablePassthrough(), \"image_url\": RunnablePassthrough()}\n",
    "        | color_prompt\n",
    "        | color_model\n",
    "    )\n",
    "\n",
    "    font_chain = (\n",
    "        {\"context\": RunnablePassthrough(), \"image_url\": RunnablePassthrough()}\n",
    "        | font_prompt\n",
    "        | font_model\n",
    "    )\n",
    "\n",
    "    # Create the final chain\n",
    "    final_chain = (\n",
    "        {\"color_result\": color_chain, \"font_result\": font_chain}\n",
    "        | final_prompt\n",
    "        | final_model\n",
    "        | output_parser\n",
    "    )\n",
    "\n",
    "    return final_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize the chain\n",
    "    accessibility_chain = create_accessibility_chain()\n",
    "    \n",
    "    # Load contexts\n",
    "    color_context = load_context('coloring_for_colorblindness.txt')\n",
    "    font_context = load_context('font_for_vision.txt')\n",
    "    \n",
    "    # Image URL\n",
    "    image_url = \"https://cdn.discordapp.com/attachments/699317920022397019/1302381353504997428/Summer-Flyer-and-Poster.png\"\n",
    "    \n",
    "    # Run the chain\n",
    "    result = accessibility_chain.invoke({\n",
    "        \"context\": {\n",
    "            \"color_context\": color_context,\n",
    "            \"font_context\": font_context\n",
    "        },\n",
    "        \"image_url\": image_url\n",
    "    })\n",
    "    \n",
    "    # Print results\n",
    "    return json.dumps(result, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Issue1\": {\n",
      "    \"Title\": \"Using a color palette of red, green, and blue\",\n",
      "    \"Description\": \"Anomalies in cone cells can interfere with a person's ability to see these colors normally\",\n",
      "    \"Suggestion\": \"Avoid using this color palette\",\n",
      "    \"Importance_score\": 0.9\n",
      "  },\n",
      "  \"Issue2\": {\n",
      "    \"Title\": \"Insufficient Font Legibility\",\n",
      "    \"Description\": \"The font used in the image may not be legible enough, particularly for people with visual impairments. The font may be too decorative or have serifs that make it difficult to read.\",\n",
      "    \"Suggestion\": \"Use a sans-serif font, such as Arial or Helvetica, which is more legible and accessible for people with visual impairments. Avoid using fonts with serifs or decorative elements that may make them difficult to read.\",\n",
      "    \"Importance_score\": 0.9\n",
      "  },\n",
      "  \"Issue3\": {\n",
      "    \"Title\": \"Inaccessible Color Palette\",\n",
      "    \"Description\": \"The color palette used in the image may not be accessible to people with colorblindness. The colors used may not have sufficient contrast and may be difficult to distinguish for people with red-green colorblindness.\",\n",
      "    \"Suggestion\": \"Use a color palette that is designed to be accessible to people with colorblindness, such as the ones provided in the IBM Design Library, Bang Wong, or Paul Tol. Consider using a tool to simulate colorblindness and test the color palette for accessibility.\",\n",
      "    \"Importance_score\": 0.8\n",
      "  },\n",
      "  \"Issue4\": {\n",
      "    \"Title\": \"Using red and green as contrasting colors\",\n",
      "    \"Description\": \"This color combination can be difficult or impossible to distinguish for people with red-green colorblindness\",\n",
      "    \"Suggestion\": \"Use magenta and green instead\",\n",
      "    \"Importance_score\": 0.8\n",
      "  },\n",
      "  \"Issue5\": {\n",
      "    \"Title\": \"Using red to highlight text\",\n",
      "    \"Description\": \"This will not work well for people with red-green colorblindness\",\n",
      "    \"Suggestion\": \"Use other colors or add other emphasis methods like italics or boldface\",\n",
      "    \"Importance_score\": 0.7\n",
      "  },\n",
      "  \"Issue6\": {\n",
      "    \"Title\": \"Inadequate Contrast\",\n",
      "    \"Description\": \"The contrast between the text and background colors may not be sufficient, making it difficult for people with visual impairments to read the text.\",\n",
      "    \"Suggestion\": \"Use a color palette that has sufficient contrast between the text and background colors. Consider using a tool to test the contrast and adjust the colors accordingly.\",\n",
      "    \"Importance_score\": 0.7\n",
      "  },\n",
      "  \"Issue7\": {\n",
      "    \"Title\": \"Red and Green Color Combination\",\n",
      "    \"Description\": \"The image uses a combination of red and green colors, which may be difficult for people with red-green colorblindness to distinguish.\",\n",
      "    \"Suggestion\": \"Avoid using a combination of red and green colors, and instead use a color palette that is designed to be accessible to people with colorblindness.\",\n",
      "    \"Importance_score\": 0.6\n",
      "  },\n",
      "  \"Issue8\": {\n",
      "    \"Title\": \"Not using a legible font\",\n",
      "    \"Description\": \"Using a font that is difficult to read can be problematic for people with vision impairments\",\n",
      "    \"Suggestion\": \"Use a non-serif font like Helvetica\",\n",
      "    \"Importance_score\": 0.6\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import weaviate\n",
    "# from weaviate.classes.init import Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wcd_url = os.environ[\"WCD_URL\"]\n",
    "# wcd_api_key = os.environ[\"WCD_API_KEY\"]\n",
    "\n",
    "# weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
    "#     cluster_url=wcd_url,                                    # Replace with your Weaviate Cloud URL\n",
    "#     auth_credentials=Auth.api_key(wcd_api_key),             # Replace with your Weaviate Cloud key\n",
    "# )\n",
    "# from langchain_together import TogetherEmbeddings\n",
    "\n",
    "# embeddings = TogetherEmbeddings(\n",
    "#     model=\"togethercomputer/m2-bert-80M-32k-retrieval\",\n",
    "# )\n",
    "# from langchain_together import ChatTogether\n",
    "# from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "# loader = TextLoader(\"./accessibility_posters_gilson2007.txt\", encoding='utf8')\n",
    "# documents = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1300, chunk_overlap=100)\n",
    "# docs = text_splitter.split_documents(documents)\n",
    "# db = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client)\n",
    "# loader = TextLoader(\"coloring_for_colorblindness.txt\", encoding='utf8')\n",
    "# documents = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1300, chunk_overlap=100)\n",
    "# docs = text_splitter.split_documents(documents)\n",
    "# db = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
